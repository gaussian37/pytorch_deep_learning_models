![1](https://i.imgur.com/YudOXEz.png)

지난 강의에서는 score function을 구하는 방법, SVM 또는 softmax를 이용하여 loss를 구하고 이렇게 구한 loss와 regularization을 이용하여 전체 loss를 구하는 방법에 대하여 알아보았습니다. 그리고 이를 통하여 알고자 하였던 ∇wL 즉, w의 변화에 따른 Loss의 변화에 대하여 알아보았습니다.

![2](https://i.imgur.com/DyjZHM2.jpg)

Optimization은 loss를 최소화 하는 W를 찾아가는 과정으로 배웠고 이를 parameter update 라고 하였습니다.

![3](https://i.imgur.com/xznAEYh.png)

gradient를 구하는 방법에는 Numerical gradient와 Analytic gradient가 있었습니다. 각각의 장단점에 대하여 공부하였고 실제적으로는 Analytic gradient를 사용하였습니다. 단, Numerical gradient를 이용하여 Analytic gradient의 값이 맞는지 확인하는 용도로 사용할 수 있었습니다.(Gradient check)

![4](https://i.imgur.com/rsDcSzQ.png)

그래서 이와 같이 Wx를 통하여 score를 얻고 score를 통하여 data loss를 얻은 후 Regularization와 더해 주어 total loss를 만듭니다. 이런 과정을 computational graph 라고 합니다. 하지만 복잡한 구조에서는 computational graph를 이용하기는 어렵습니다.

![5](https://i.imgur.com/KLICKOs.png)

위와 같이 복잡한 구조에서는 computational graph를 이용하여 loss를 구하는 것은 너무 버거운 일입니다. 그래서 이번 강의에서는 하나 하나의 모듈로 계산해 나가는 방식을 학습해 보도록 하겠습니다.

![6](https://i.imgur.com/hk4RLc6.png)

f(x, y, z) = (x+y)z 라고 하였을 때 임의의 값들을 이용하여 graph를 그려보았습니다. <br>
위의 graph 처럼 왼쪽 → 오른쪽으로 흘러가는 graph를 forward pass 또는 forward-propagation이라고 합니다.<br> 
여기서 우리가 구해야 하는 것은 gradient 입니다. 즉, input이 마지막 단에 어느 정도 영향을 미치는가를 구하고 싶은 것 입니다. <br>
따라서 gradient를 구하기 위해, + 연산에 매개변수 q를 두도록 하겠습니다.

![7](https://i.imgur.com/8lZ0hiF.png)

그림에서 보시다시피 매개변수 q를 도입하였고, f = qz로 표현할 수 있습니다. <br>
출력 단계의 f 부터 미분을 해주게 되면 각각 q와 z에 대하여 미분할 수 있습니다.<br>
∂f / ∂q = z, ∂f / ∂z = q임을 알 수 있습니다. <br>
q = x + y 이므로 ∂q / ∂x = 1, ∂q / ∂y = 1이 되는 것 또한 확인할 수 있습니다.

**우리가 원하는 것은 input 에 대한 마지막 단계에서의 영향력** 입니다. <br>
따라서 **입력단 x, y, z에 대한 출력단의 변화율인 ∂f/∂x, ∂f/∂y, ∂f/∂z 값이 필요**합니다.<br>
이를 위해서 backward pass 또는 back-propagation을 해야 합니다.  forward-propagation과 반대로 입력층 ← 출력층 으로 전달되는 값을 구해야 입력단에 대한 출력단의 변화율을 구할 수 있습니다.

![8](https://i.imgur.com/etgaCH9.png) 

먼저, 출력단 f에 대한 미분 즉, ∂f / ∂f = 1이 됩니다. 여기서 구분한 사항은 위쪽 녹색 값은 FP의 값이고 빨간색은 BP의 gradient 값입니다. 여기서 BP의 gradient는 각각의 노드 값들을 이용하여 f를 미분한 것입니다. 즉, q에서의 gradient는 ∂f / ∂q 가 되는 것이고 x에서의 gradient는 ∂f / ∂x 가 되는 것입니다.

![9](https://i.imgur.com/4XKm2hO.png)

∂f / ∂z = q를 이용하여 쉽게 gradient = 3을 구할 수 있습니다. <br>
이 때 ∂f / ∂z = 3의 의미를 이해해보면 **z의 값을 h만큼 변화하면 f의 값은 3*h 만큼 변화**한다는 뜻입니다. 즉, 입력의 3배만큼의 변화를 출력에서 가지게 된다는 뜻이고 그래서 변화율이 3이되게 됩니다. 

![10](https://i.imgur.com/Ia4JKMV.png)

이번에는 q에 대한 출력 값의 변화율을 보면 ∂f / ∂q = z = -4입니다. 이것 또한 q를 h만큼 변화시킨다면 f는 -4*h만큼 변화한다는 뜻입니다. 

![11](https://i.imgur.com/zLFRWpd.png)

이제 y에 대한 f의 변화율을 구해보려고 합니다. 하지만 y에 대한 f의 변화율을 바로 구하기는 어려워 chain rule을 이용하려고 합니다. 
결국 ∂f / ∂y = (∂f / ∂q) * (∂q / ∂y)로 표현할 수 있고, 앞에서 저희는 ∂f / ∂q의 값을 구하였습니다. 따라서 ∂f / ∂y = (-4) * (1)  = -4가 됩니다.
이 의미는 y가 h만큼 변화하였을 때 f는 -4*h만큼 변화한다는 뜻입니다. 그리고 q의 경우에는 y와 같은 gradient 값을 가지고 있습니다. 따라서 **y가 h만큼 변화하였을 때 q 또한 h만큼 변화**하게 됩니다.

![12](https://i.imgur.com/c6NUH3b.png)

∂f / ∂y를 구하는 chain rule의 ∂q / ∂y 는 직접적인 gradient 값이 되기 때문에 local gradient라고 하고 반대로 ∂f / ∂q 를 global gradient 라고 합니다. 

![13](https://i.imgur.com/7Rhr9Gu.png)

마지막으로 ∂f / ∂x 의 값은 ∂f / ∂y를 구할 때와 동일 합니다.
∂f / ∂x = (∂f / ∂q) * (∂q / ∂x) = -4 * 1 = -4 가 됩니다. 따라서 x의 h만큼 변화에 따른 f의 변화량은 -4*h 이고, q의 변화량은 h가 됩니다.

![14](https://i.imgur.com/K7Nk61N.png)

간단하게 gradient를 구하는 방법에 대하여 알아보았습니다. 여기서 반드시 알아야 하는 내용은 이 함수를 하나의 layer 또는 gate 로 표현하였고 FP(forward propagation) 과정 중이라 생각하면 FP 중에 바로 local gradient를 구할 수 있습니다. gradient를 구할 때, gradient = global gradient * local gradient 라고 학습하였습니다. 

![15](https://i.imgur.com/FLfHYg6.png)

다시 이전 슬라이드를 보면 FP 중에 local gradient를 구할 수 있었습니다. 예를 들어 q = x+y 에서 ∂q / ∂x = 1, ∂q / ∂y = 1을 구하였고 f = qz 에서 ∂f / ∂q = z , ∂f / ∂z = q를 구할 수 있었습니다. 

![16](https://i.imgur.com/YQzPu4x.png)

따라서 **핵심 내용은 local gradient는 FP 시 계산하여 메모리에 저장해 둔다는 것이 핵심**이 되겠습니다.

![17](https://i.imgur.com/aHJqGQa.png)

위 자료에서 global gradient는 ∂L / ∂z 가 되는데 이 값은 Back propagation을 하는 과정에서만 구할 수 있습니다.

![18](https://i.imgur.com/dSs1yDZ.png) 

즉, **정리하면 FP에서는 local gradient를 구하고 BP에서는 global gradient를 계산을 하여 최종적으로 BP에서 global gradient * local gradient 로 gradient를 얻을 수 있습니다. **따라서 위 자료를 기준으로 ∂L / ∂x = global gradient * local gradient = (∂L / ∂z) * (∂z / ∂x)가 되고 ∂L / ∂y = global gradient * local gradient = (∂L / ∂z) * (∂z / ∂y) 가 됩니다. 

![19](https://i.imgur.com/rnS84dz.png)

∂L / ∂x 와 ∂L / ∂y는 계속하여 BP를 통해 계속 전파 됩니다.<br>
**만약 BP 시 전파 되는 노드가 여러개라면, 예를 들어 z 한개가 아닌 z1, z2, z3, ... 가 f로 합쳐진다면 그 값들을 다 합쳐주면 됩니다.**

![20](https://i.imgur.com/P3bcl2g.png)

이번에는 조금 더 복잡한 예를 살펴 보도록 하겠습니다.<br>
총 5개의 input이 있고 f(w, x) 는 시그모이드 함수 형태를 가진다고 가정합시다.<br> 
이것을 computational graph로 그리면 위의 graph 처럼 그릴 수 있습니다. <br>
최종적으로 구해야 하는 gradient는 총 5개가 있습니다. ∂f / ∂w_0, ∂f / ∂w_1, ∂f / ∂w_1, ∂f / ∂x_1, ∂f / ∂w_2 즉, **input의 갯수 만큼 gradient가 필요로 하게 됩니다.**

![21](https://i.imgur.com/RDpXfuQ.png)

먼저 간단한 미분은 먼저 하고 시작해 보겠습니다. 

![22](https://i.imgur.com/Y18aLkp.png)

마지막 출력층을 f라고 하면 ∂f / ∂f  = 1이므로 항상 1부터 시작합니다.<br>
첫 번째 gate는 1/x 입니다.

![23](https://i.imgur.com/oTIBazc.png)
1/x gate에 대한 미분을 이용하여 gradient를 구하려면 gradient = global gradient * local gradient 을 이용해야 합니다. <br>
임의로 1/x gate 이전을 a 라고 하고 이후를 L 이라고 한다면, 이 단계에서 구해야 하는 것은 ∂L / ∂a 이고 이것을 global gradient * local gradient로 풀어서 쓰기 위해 b를 도입하여  ∂L / ∂a = (∂L / ∂b) * (∂b / ∂a)라고 쓸 수 있습니다.<br> 여기서 (∂L / ∂b) = global gradient가 되고 (∂b / ∂a) = local gradient가 됩니다. <br>
정리하면 global gradient = (∂L / ∂b) = ∂f / ∂f = 1이고 local gradient = (∂b / ∂a) = -(1/1.37^2) 이 됩니다.

![24](https://i.imgur.com/FLP3bzW.png)

따라서 위 자료와 같이 (-1 / 1.37^2) * (1.00) = -0.53으로 BP를 업데이트 할 수 있습니다. 

![25](https://i.imgur.com/52R97Eh.png)

이번에는 +1 gate에 대한 BP를 진행해 보겠습니다.<br>
C + x의 x에 대한 미분은 1이 됩니다.

![26](https://i.imgur.com/RFC8hru.png)

마찬가지로 gate 이전을 a, 이후를 L이라고 표현을 하면 b를 도입하여 ∂L/∂a = ∂L/∂b * ∂b/∂a가 됩니다. local gradient 값은 1이 될 것이고 global gradient 값은 -0.53이므로

![27](https://i.imgur.com/gii7Xqp.png)

결과적으로 +1 gate에 대한 BP를 업데이트 하면 gradient = (1) * (-0.53) = -0.53이 됩니다. 

![28](https://i.imgur.com/kqEeL6a.png)

다음으로 exp에 대한 gradient를 계산해 보겠습니다. 앞선 계산과 동일한 방식으로 gradient를 계산하면 global gradient * local gradient 로 계산할 수 있고 global gradient =  -0.53이고 local gradient 는 exp 미분값에 따라 exp(-1)이 됩니다.

![29](https://i.imgur.com/OWc8hAr.png)

따라서 exp gate에 대한 gradient = (e^-1) *(-0.53) = -0.20이 됩니다.

![30](https://i.imgur.com/oqXi2pM.png)

다음으로 * (-1) gate에 대한 gradient를 구하면 이전 방식과 동일하게 global gradient * local gradient로 구할 수 있습니다.
global gradient = -0.20이고 local gradient = -1입니다. 

![31](https://i.imgur.com/YYj6alZ.png)

따라서 *(-1) gate에 대한 gradient = (-1) * (-0.20) = 0.20 이 됩니다. 

![32](https://i.imgur.com/6l16RMm.png)

다음으로 + gate에 대한 gradient를 구해보겠습니다.<br>
예를 들어 x + a 의 x에 대한 미분을 구하면 1이 되듯이 local gradient = 1이 되고 global gradient = 0.2가 됩니다. 따라서 양쪽 모두 gradient = (1) * (0.2)가 됩니다.<br>
**+ 연산 같은 경우에는 gradient distributor라고 합니다. gradient를 global gradient와 동일한 값으로 전달해 주기 때문**입니다.

![33](https://i.imgur.com/WksJMNs.png)

따라서 나머지 + 연산 또한 gradient distributor를 적용하였습니다.<br>
다음으로 볼 부분은 * gate로 w0과 x0의 gradient를 구하기 위해 이전 내용에서 f = qz에서 ∂f / ∂q = z , ∂f / ∂z = q인 것을 이용해 보겠습니다.<br>
∂L / ∂w0 = global gradient * local gradient = (∂L/∂b)*(∂b/∂w0) = (0.2) * (-1) = -0.2<br>
∂L / ∂x0 = global gradient * local gradient = (∂L/∂b)*(∂b/∂x0) = (0.2) * (2) = 0.4

![34](https://i.imgur.com/R63oiQH.png)

따라서 위와 같이 ∂f / ∂w0, ∂f / ∂x0을 구할 수 있습니다. 위의 자료에서 x0에 대한 gradient는 0.39가 아닌 0.4가 맞습니다. w1과 x1의 gradient도 동일하게 계산해 보면 ∂f / ∂w1 = -0.4, ∂f/∂x1 = -0.6이 됩니다. 

![35](https://i.imgur.com/kVwKVik.png)

여기서 추가적으로 확인을 해야 하는 내용은 sigmoid function의 미분 입니다.<br>
σ(x) = sigmoid function 이라고 하면 ∂σ(x) / ∂x = (1-σ(x))σ(x)가 됩니다. <br>
자료의 sigmoid gate 내의 연산을 σ(x)의 미분값을 이용하여 gradient를 계산하면 쉽게 계산할 수 있습니다.

![35-1](https://i.imgur.com/xJsrYJ6.png)  

![36](https://i.imgur.com/gTF7wmJ.png)

따라서 gradient = global gradient * local gradient = (1.00) * (1- σ(1.00))σ(1.00) = (1.00) * (1 - 0.73)(0.27) = 0.20이 됩니다.

![37](https://i.imgur.com/7EY1NKl.png)

앞에서 배운 내용을 다시 정리를 하면,<br>
**① add gate : gradient distributor <br>**
- 이 전의 gradient 값을 그대로 전파를 해주는 역할. 왜냐하면 local gradient 값이 1이기 때문입니다.<br>
**② max gate : gradient router <br>**
- FP시 큰 값은 local gradient가 1이 되고 작은 값은 0이 됩니다.<br> 
**③ mul gate : gradient switcher<br>**
- FP 시 두 입력 값을 switch 한 값이 각각의 local gradient가 됩니다.<br>

![38](https://i.imgur.com/z5i7JZ0.png)

뒷 단이 여러개의 분기되어서 BP 시 합쳐질 경우 여러개의 gradient를 더해주면 됩니다. 만약 여러개 분기 중 하나의 gradient 결과가 0.2 이고 나머지가 0.5라면 단지 더하기만 하여 BP시 합쳐지는 노드에서는 각각의 gradient 값을 더하기만 하면 됩니다. 따라서 합쳐지는 gate의 gradient는 0.7이 됩니다.

![39](https://i.imgur.com/sgWuTU3.png)

실제 구현을 한번 보시면 FP를 forward 함수로 만들어 input을 받은 다음 loss를 return해 줍니다. BP 또한 backward 함수를 만들어 input에 대한 gradient 값을 return해 줍니다.  조금 더 자세하게 살펴보겠습니다.

![40](https://i.imgur.com/yVsM3vB.png)

FP 같은 경우 z = x*y를 return해 주면 되고, BP에서는 (∂L / ∂z) 즉, global gradient를 입력 값으로 받고 이를 통해서 (∂L / ∂x) 와 (∂L / ∂y)를 return 하게 됩니다.<br>
이것을 조금 더 구체화 해서 보겠습니다.

![41](https://i.imgur.com/Mvu85yx.png)

backward 함수에서 self.x 와 self.y는 각각 FP에서의 x와 y를 저장한 값이고 이 값은 BP 에서 각각 (∂z/∂y), (∂z/∂x)가 됩니다. 즉, FP를 할 때 local gradient 미리 저장한 것으로 생각하면 됩니다.
**즉 정리하면, FP를 할 때, local gradient를 저장해 두었다가 BP를 할 때 사용합니다.**

![42](https://i.imgur.com/47YnbbV.png)

조금 더 현실적으로 바라보면 x, y, z 모두 vector가 됩니다. 
∂L / ∂x = (∂L / ∂z ) * (∂z / ∂x)에서 **global gradient = (∂L / ∂z) 는 vector**가 될 것이고 **local gradient = (∂z / ∂x)는 matrix 가 됩니다. 정확히는 Jacobian matrix**가 됩니다.

![43](https://i.imgur.com/gZFfySg.png)

이 때, Vectorized operation이 일어나게 됩니다. 예를 들어 4096 차원의 input vector가 들어오게 되면 f(x) = max(0, x) : relu로 non-linearity 성질을 더하게 되고 4096개의 output vector가 출력이 된다고 가정합시다.<br>
여기서 중간 단계인 (∂z / ∂x)는 Jacobian matrix가 되는데 이 matrix의 사이즈가 얼마가 될까요?<br>
Input vector는 (4096 x 1)의 열벡터가 될 것이고, Output vector의 경우 똑같이 (4096 x 1) 의 열벡터를 가지므로 Jacobian matrix의 경우 사이즈가 (4096 x 4096)이 되어야 합니다.<br>
즉, ∂L / ∂x = global gradient * local gradient = (∂L / ∂z ) * (∂z / ∂x) 이고 **(∂L / ∂z) 는 (4096 x 1) vector **이고 **(∂z / ∂x)는 (4096 x 4096) matrix**가 되어 ∂L / ∂x =  (∂L / ∂z ) * (∂z / ∂x) = (∂z / ∂x) * (∂L / ∂z ) = (4096 x 4096) * (4096 x1) =(4096 x 1)이 됩니다.  <br>
그러면 이 때 Jacobian matrix는 어떤 형태를 가질까요? <br>
Identity matrix와 유사한 형태를 가지게 됩니다. 즉, 대각선에 1, 0이 혼재되어 있는 형태인 sparse structure matrix를 가지게 됩니다. <br>

![44](https://i.imgur.com/SgwuoSn.png)

실제 사용할 때에는 mini-batch 형태로 사용하므로 batch size = 100 이라면 한 번에 100개씩 input vector가 들어오게 되므로 실질적으로 Jacobian matrix = (409,600 x 409,600)의 거대한 사이즈를 가지게 됩니다. 

![45](https://i.imgur.com/X6o5gkH.png)

지금 까지 배운 내용 정리입니다. 이번 강의에서는 BP에 대하여 자세히 알아보았습니다.

![46](https://i.imgur.com/hm3VjMH.jpg)

지금부터는 Neural Network에 대하여 알아보도록 하겠습니다.

![47](https://i.imgur.com/QaBb7kt.png)

기존에 Linear score function을 구할 때 f = Wx로 간단하게 구하였습니다.<br> 
이제 신경망에서의 Network 구성을 알아보기 위해 간단한 예로 2-layer Neural Network를 구성해 보려고 합니다. 이 때는 f = W2*max(0, W1x)로 식을 구성할 수 있습니다. 여기서 사용된 max(0, x) 함수는 Activation 함수의 일종인 relu 입니다.<br> Activation에 대해서는 후에 더 자세하게 알아보겠지만, 이 기능은 Non-linearity 를 적용하는 함수라고 생각하면 됩니다.<br>
예를 들어 CIFAR-10 데이터를 사용한다고 생각해 봅시다. CIFAR-10 데이터는 32 x 32 x 3의 이미지를 제공합니다.<br>
따라서 32 * 32 * 3 = 3072개의 픽셀을 가지고 있는 열벡터로 표현할 수 있습니다. <br>
이 벡터가 W1이라는 weight와 연산이 되어 중간단인 hidden layer = 100개의 노드를 구성할 수 있고 이 벡터는 W2라는 weight와 연산이 되어 최종적으로 Score인 10개의 class를 가지는 output layer 벡터로 표현할 수 있습니다. <br>
	
![48](https://i.imgur.com/wDjFvAZ.png)

앞에서 배운 data-driven approach 중 KNN의 한계를 다시 한번 생각해 보면 object들에 다양한 형태, 색상 및 방향등이 있는데 이 특징들을 하나의 이미지로 merge를 하였었습니다. merge 하는 이유는 각각의 class에는 오직 1개의 classifier가 존재하기 때문입니다. 예를 들어 자동차를 분류하는 classifier에는 다른 색상의 자동차가 많음에도 불구하고 학습한 데이터가 빨간색 자동차 이므로 빨간색으로만 구분하는 한계를 가지기도 하였습니다. 또한 말 같은 경우에는 왼쪽을 향하는 말과 오른쪽을 향하는 말을 하나의 classifier에 표현하는 한계를 보이기도 하였습니다.<br>

반면 Neural Network에서는 위의 슬라이드를 예로 봤을 때, hidden layer에 총 100개의 노드가 있고 그 hidden node 각각이 하나의 feature를 담당한다는 식으로 이해를 하면 됩니다. 예를 들어 특정 한개의 hidden node는 앞쪽을 바라보고 있는 빨간색 자동차를 담당하는 노드가 됩니다. 여기서 사용된 hidden layer의 갯수는 hyper parameter로 성능이 가장 잘 나올 수 있도록 선정하는 것이 중요합니다.<br> 

다시한번 정리를 하면, **Data-driven approach에는 parametric approach와 non-parametric approach가 있고 non-parametric approach의 대표적인 예는 KNN이었는데 KNN의 경우 one-class, one-classifier 으로 성능에 한계를 보였습니다. 하지만 parametric approach의 대표적인 Neural network의 경우 one-class, multi-classifier로
이미지 분류에 좋은 성능을 보입니다.** 

![49](https://i.imgur.com/OrBR0TU.png)

물론 3개 이상의 layer를 가지는 Neural network도 구성할 수 있습니다. Activation을 Relu를 사용하였을 때 f = W3*max(0, W2*max(0, W1*x))와 같이 사용하면 됩니다. 

![50](https://i.imgur.com/aiYhtSI.png)

Python 코드를 이용하여 2-layer Neural Network를 구성한 예입니다.

![51](https://i.imgur.com/6MQNxRu.png)

생물학적인 측면에서 Neuron에 대하여 알아보면 Neuron에는 cell body라는 핵심이 있고 input이 들어오는 dendrite, output이 나가는 axon이 있습니다. 각각의 neuron이 여러개로 합쳐지면서 전달과정이 반복되어 집니다. <br>
x0(axon from a neuron)이라는 데이터가 들어와서 w0(synapse)이라는 가중치와 연산을 하고 w0*x0(dendrite) 이 cell body 입력으로 들어오게 됩니다. cell body로 들어온 입력들은 summation이 된 후 activation function을 적용하여 Non-linearity를 만들어 주고 output(axon)을 통하여 다음 neuron으로 전달합니다.<br>

activation function 중에 전통적으로 많이 사용되었던 것이 sigmoid function 이었습니다. 가장 많이 사용된 이유는 **값의 범위가 (0, 1) 사이에 수렴이 되고 특정 뉴런의 영향성을 마치 확률 처럼 (0, 1) 사이의 값으로 표현하여 측정하기 쉽기 때문**이었습니다. 

![52](https://i.imgur.com/TYuqIxx.png)

sigmoid 함수를 코드로 표현하면 위와 같습니다. input 값으로 vector로 받고 cell body에서 weight와 matrix multiplication 한 값을 summation 합니다.<br>
그 다음 sigmoid function을 적용하여 non-linearity를 만들어 주고 이 값을 return 하여 다음 neuron으로 전달해 줍니다.

![53](https://i.imgur.com/CrEIhe0.png)

주의해야 할 점은 인공 신경망이 인간의 두뇌와 비슷하다고 말 할 수 있는가 입니다.<br>
생물학적인 neuron은 그 정류도 다양할 뿐 아니라 dendrite 단계에서 훨씬 더 non-linear한 연산을 하고 synapse 또한 더 복잡한 연산을 합니다. 따라서 인공 신경망이 실제 신경망을 모방을 하였지만 복잡성 측면에서는 훨씬 단순하므로 완전히 유사하다고 생각하다는 것은 주의해야합니다.

![54](https://i.imgur.com/zjt1AW0.png)

앞에서 살펴본 Activation에는 대표적으로 위와 같은 함수 들이 있습니다. 전통적으로 많이 사용된 Activation에는 sigmoid 및 tanh가 있었으나 요즘 많이 사용하는 함수는 ReLU입니다. ReLU에도 개선해야 할 점들이 있어 Leaky Relu, ELU등도 나왔습니다. 이와 관련된 내용은 추후에 알아보도록 하겠습니다.

![55](https://i.imgur.com/AlN8EHM.png)

Neural Network의 구조에 대해서 알아보겠습니다. 왼쪽 Neural network는 2-layer입니다. 기본적으로 Layer의 구분 기준은 Weight를 가지는 것을 기준으로 합니다. input layer의 경우 weight가 없으므로 layer에서는 빠지게 되어 왼쪽 model은 2-layer neural network 입니다. 또는 1-hidden layer neural network라고 합니다.<br> 
오른쪽 model은 3-layer Neural Net 또는 2-hidden layer neural network 라고 합니다.<br>
layer들의 연결성을 보면 모든 node들이 연결이 되어 있습니다. 이렇게 모든 Node 들이 연결된 것을 FC(Fully Connected) layer라고 합니다. 

![56](https://i.imgur.com/T6RNGzp.png)

FC layer로 구성하는 이유는 효율적으로 계산을 할 수 있기 때문입니다. 

![57](https://i.imgur.com/nwIKDTw.png)

FC를 이용하면 Layer간의 연산을 간단하게 한 줄로 표현할 수 있기 때문에 사용합니다.

![58](https://i.imgur.com/AHntRJX.png)

위 예는 Layer의 갯수를 어떻게 설정하느냐에 대한 예입니다. layer의 갯수가 많아질수록 capacity가 높아져서 분류를 하는 능력이 좋아짐을 볼 수 있습니다. 

![59](https://i.imgur.com/oWrr5vB.png)

단 조심해야 할 점은, Neural Net의 Layer의 갯수가 regularizer의 역할을 하는 것은 아님을 명심해야 합니다. 일반화를 하기 위해서는 regularizer strength를 더 높여야 합니다. λ값을 더 크게 가질수록 일반화가 되어 training 데이터에 overfitting되지 않고 test data에 일반화 되는 효과를 볼 수 있습니다.
즉, **데이터의 overfitting이 일어나지 않도록 network를 잘 구성하는 방법은 layer의 갯수를 조절하는 것이 아니라 regularizer strength을 더 높여주어야 하는 것** 입니다.
따라서 앞의 슬라이드와 현재 슬라이드를 합쳐서 보면 **Neural Network는 regularization을 잘 하였다는 전제 하에서는 layer가 깊으면 깊을수록 좋습니다. **

![60](https://i.imgur.com/ZtlAoa6.png)