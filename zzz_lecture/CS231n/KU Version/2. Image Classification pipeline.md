# 2. Image Classification pipeline #

※ 출처 : [http://dsba.korea.ac.kr/wp/?page_id=167](http://dsba.korea.ac.kr/wp/?page_id=167)

※ 영상 : [링크](https://www.youtube.com/watch?v=-8TphLTIXjg&list=PLetSlH8YjIfXMONyPC1t3uuDlc1Mc5F1A&index=2)

※ 작성자 : [김진솔(gaussian37)](http://github.com/gaussian37)

이번 강의 순서는 다음과 같습니다.<br>
- Image classification에 대하여 알아보고 그것이 어려운 이유를 설명하겠습니다.<br>
- KNN 기반의 이미지 분류기에 대하여 알아보겠습니다.<br>
- Linear iamge 분류기에 대하여 알아보겠습니다.<br>

![1](https://i.imgur.com/8h85jWu.png)

이미지는 먼저 RGB 형태로 3층의 구조를 갖는 육면체 입니다. 8 bit RGB 기준으로 각 픽셀당 [0, 255] 값을 가집니다. </br>

![2](https://i.imgur.com/ET19vZF.png)

기존에 사용되었던 정형 데이터들을 Class1, 2 등으로 나누는 것을 이미지에 대응시키면<br>
이미지(x)와 레이블(y)를 classifier에 통과 시켜 분류를 하는 구조로 변환하여 생각할 수 있습니다.<br>

![3](https://i.imgur.com/2pPlgij.png)

이미지를 분류하는 데 어려운 점 중 하나는 이미지의 형상, 바라보는 관점, 회전, 줌 등등 다양한 변수에 따라서 모두 다른 이미지로 기계는 받아들인다는 점입니다. 

![4](https://i.imgur.com/MVbCLEL.png)

빛의 밝기에 따라서 어려운 점이 생길 수도 있습니다. 사람의 경우 추론을 해서 같은 고양이라고 볼 수 있지만 기계는 쉬운 문제가 아닙니다. 

![5](https://i.imgur.com/FN6Og8F.png)

위와 같이 형태가 변형이 되었을 때의 문제점도 있습니다.

![6](https://i.imgur.com/aHxolDe.png)

구조들에 숨어있는 경우 또한 어려운 문제에 속합니다.

![7](https://i.imgur.com/fejFWcB.jpg)

배경과 너무 유사한 경우 물체를 확인하기 어렵습니다. 

![8](https://i.imgur.com/grCk5cf.png)

같은 종류 내에서 분류를 하기에 어려운 문제가 있습니다.

![9](https://i.imgur.com/sjT2TaF.png)

이번 강의에서는 Data 기반의 Image classification을 ML을 적용하여 classifier를 만들어 이미지 분류를 해보고 classifier의 성능을 평가해 보는 과정을 소개하겠습니다.

![10](https://i.imgur.com/lYo480w.png)

위는 KNN 기반의 이미지 분류기 입니다. KNN은 Lazy model 이라고도 알려져 있습니다.<br>
training data가 들어왔을 때, 즉각적으로 모델을 형성하는 것이 아니라 데이터를 가지고 있는 상태에서<br>
추후에 test 데이터가 들어오게 되면 test 데이터와 training 데이터 사이의 거리를 계산한 다음에<br>
근처에 있는 neighbor를 기반으로 새로 들어온 test 데이터에 label을 할당해주는 모델입니다.

KNN 알고리즘을 사용하기 전에 선정해주어야 할 Hyper-parameter는 다음과 같습니다.<br>
1) K : 주변의 neighbor 몇개를 살펴 볼 것인가를 정해 주어야 합니다. <br>
2) Voting :  Voting 하는 방법 즉, 주변의 neighbor에 똑같은 voting 값을 줄 것인지,<br>
&nbsp;&nbsp;&nbsp;&nbsp;아니면 weight를 다르게 하여 가까운 neighbor에 비중을 줄것인지 등을 정해야 합니다. <br>
3) Distance metric : 거리 measuure 할 때 어떤 방법을 사용할 것인지를 정해야 합니다.<br> 

![11](https://i.imgur.com/FarvoNH.png)

Distance metric에 대하여 간단하게 정리를 해보겠습니다.<br>
1) L1 distance : 절대값 차이<br>
2) L2 distance : 유클리디안 거리 <br>
위의 4 x 4 의 test/training image가 있을 때, L1 Distance는 각각의 픽셀의 차이를 절대값을 취한 뒤 summation 하면 됩니다. 결과는 456입니다.

![12](https://i.imgur.com/8IODltX.jpg)

cs231n에서 소개하고 있는 데이터 셋은 CIFAR-10 입니다. 10개의 class를 가지는 이미지 데이터 셋이고, 총 50,000개의 training image와 10,000개의 test image를 가지고 있습니다. 각각의 이미지는 32 x 32 x 3이 형태를 지니고 있습니다.

![13](https://i.imgur.com/Bra7TpP.png)

※ 주피터 노트북에서 실행 시 %matplotlib inline 을 입력해줘야 jupyter 상 이미지가 표시 됩니다.<br>
파이썬의 sklearn 라이브리에 있는 hand-written digit 데이터를 받아서 실습을 해보겠습니다. 위는 실제 데이터를 입력 받아서 visualization을 한 내용입니다.<br>
date 셋의 0,1,2,3 인덱스 데이터를 출력해보니 8 x 8 grayscale 이미지로 결과는 위와 같습니다. 1번 인덱스를 출력해보면 숫자에 해당하는 부분만 숫자가 입력되어 있습니다. 원본 이미지는 숫자 부분만 밝고 나머지는 검은색 이지만(0) cm.gray_r 옵션으로 반전시킨 형태입니다.<br>

![14](https://i.imgur.com/IrJl35V.png)

여기서 nearst 클래스를 정의해 보도록 하겠습니다.<br> 
- train method에서는 image X와 label Y를 받아서 클래스 내부에 저장합니다.<br>
- predict method에서는 새로운 test data가 들어왔을 때, 원래 가지고 있던 training data와 L1 distance를 계산하여 가장 가까운 label 값을 할당해 줍니다.

![15](https://i.imgur.com/XoBBar3.png)

실제로 데이터에다가 직접 적용해 보면, 데이터를 training set과 test set으로 나누어 주고 Nearstneighbor라는 객체를 선언한 다음에 train method를 통해 값을 전달해 줍니다. predict method를 통해 Y predict 값을 반환 받습니다. 

![16](https://i.imgur.com/A0nhJWr.png)

1-NN classifier를 하였을 때와 5-NN classifier를 하였을 때, 결과가 달라짐을 확인할 수 있습니다.<br>
어떤 k를 적용하느냐에 따라서 결과가 달라질 수 있는데, 위의 코드는 L1 distance가 가장 작은 것 1개를 확인한 1-NN 이고<br>
만약 5-NN을 사용하면 L1 distance가 작은것 5개를 확인 후 가장 많은 class에 속하는 것이 prediction이 됩니다.

![17](https://i.imgur.com/rmEscUs.png)

K의 수는 항상 크다고 좋은 것이 아닙니다. 일단 K가 커질수록 계산량이 많아집니다. 그리고 K의 크기가 커진다고 Prediction이 항상 좋아지는 것도 아니므로 적정 값을 찾아야 합니다.즉, hyper-parameter 튜닝이 필요합니다.

![18](https://i.imgur.com/eRLDSSz.png)

hyper parameter를 조정하기 위해서는 cross-validation을 적용할 수 있습니다.<br>
※ k-fold cross-validation의 k와 K-NN의 K는 완전 무관 합니다.<br>
k-fold cross-validation을 적용하려면 training data를 k개로 나눠야 합니다.<br>
1-fold를 적용하는 것은 1개의 Training data 군을 만들고 1개의 test data 군을 만듭니다. test data는 학습할 때 전혀 사용하지 않는 데이터 셋입니다. test data를 통하여 범용성을 확인하게 됩니다.<br>
만약 5-fold를 사용하려면 Training data를 5개로 나누게 됩니다. 이 때 1개의 군을 validation data set으로 사용하고 나머지 4개는 training data로 사용합니다. 그러면 총 5가지의 validation set을 사용할 수 있고 이 때의 성능은 5번을 수행한 후 결과를 평균을 내서 성능을 측정합니다.<br>
k-fold를 사용하는 이유는 최대한 많은 validation data를 사용해 봄으로써 overfitting을 방지하는 것입니다.<br>
5-fold cross validation이 예로 많이 사용되는 이유는 데이터 셋을 나누는 비율이 80/20으로 training data / test data로 나누고 80 중에서 80/20으로 training data / validation data로 나누는 것이 경험적으로 좋기 때문입니다.<br>

![19](https://i.imgur.com/ZYGFN3m.png)

위 자료는 5-fold CV를 적용하고 KNN의 K를 변경해 가면서 accuracy를 적용한 결과 입니다. (x축,y축 기준이 바껴야 한다고 생각합니다...)<br> 각 점은 5-fold에서의 값이고 선들은 5-fold들의 평균을 이은 값입니다. KNN의 K를 변경하면서 실험한 결과를 보면 10-NN정도에서 accuracy가 가장 높음을 알 수 있습니다.(데이터에 따라 다를 수 있습니다.)

따라서 KNN을 사용할 때에는 5-fold 기준으로 최적의 K를 찾은 다음에 적용해 보면 되겠습니다.(꼭 5-fold일 필요는 없습니다.)

![20](https://i.imgur.com/NogIuy4.png)

하지만 이미지 데이터에는 KNN 이미지 분류기를 왠만하면 사용하지 않습니다. 이유는 성능이 너무 안좋습니다.<br>
original 데이터를 다른 내용으로 변형하였을 때, distance가 같으면 모두 같은 이미지로 분류하기 때문에, 정확도가 떨어집니다. 즉, 이미지 고유의 특성을 잡을 수 없습니다.

![21](https://i.imgur.com/HvfgL8I.png)

그 다음으로는 Linear Image classification에 대하여 알아보겠습니다.<br>
입력받은 고양이 이미지는 32 x 32 x 3의 3072개의 숫자로 이루어진 이미지로 생각할 수 있습니다.<br>
이 입력값에 Weight를 곱하고 bias를 더해줌으로써 3072 x 1 의 열벡터를 10 x 1로 변형해 보도록 하겠습니다.<br>
10개의 class가 있다고 할 때 10 x 1의 값들은 각각의 class에 할당되는 확률을 나타냅니다.<br> 
그러면 W는 3072 → 10으로 매핑해주는 매트릭스이고 b는 그 결과에 더해주는 값으로 최종 결과를 만들어 냅니다.

![22](https://i.imgur.com/AIxzcKn.png) 

이미지가 예를 들어 4x1 로 4개의 pixel만 가지고 있다고 가정해 봅시다.<br>
class는 cat/dog/ship 3개가 있습니다. 이때 연산을 해보면 최종적으로 3 x 1의 결과를 얻을 수 있고 가중치가 가장 큰 dog로 분류되어 집니다. 일반적으로 최종 형태에는 softmax와 같은 함수를 이용하여 확률로 나타냅니다. 

![23](https://i.imgur.com/mvbus2Q.png)

학습을 완료한 후에는 weight를 확인해 볼 수 있습니다. plane을 학습한 weight는 파란색(하늘?)이 많음을 알 수 있습니다.<br>
자동차 같은 경우에는 빨간색 차 형태로 weight가 나타내어집니다. 학습 시 빨간색 차를 사용 했음을 유추할 수 있습니다.

![24](https://i.imgur.com/a1u68EA.png) 

Weigt를 랜덤하게 주게 된다면 당연히 분류가 잘 안됩니다. 물론 우연히 위의 자동차와 같이 맞을 수는 있지만 의미가 없습니다.<br>
그러면 학습시 필요한 작업이 바로 W를 이미지에 맞게 학습하여 최적화 하는 것입니다. 앞으로는 loss를 구하는 방법 부터 loss를 어떻게 최적화 할 지 알아보도록 하겠습니다.
