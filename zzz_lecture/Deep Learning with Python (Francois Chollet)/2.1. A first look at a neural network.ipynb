{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deep Learning with Python (Francois Chollet)\n",
    "\n",
    "## 2.1. A first look at a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.620752Z",
     "start_time": "2018-05-03T00:46:12.153605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infoe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Loading the MNIST dataset in Keras\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train_images* and *train_labels* form the *training set*, the data that the model will learn from.\n",
    "The model will then be tested on the test set, *test_images* and *test_labels*.\n",
    "The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9. The images and labels have a one-to-one correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.628273Z",
     "start_time": "2018-05-03T00:46:14.621755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.638812Z",
     "start_time": "2018-05-03T00:46:14.629275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.648326Z",
     "start_time": "2018-05-03T00:46:14.639803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.657350Z",
     "start_time": "2018-05-03T00:46:14.649328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.665371Z",
     "start_time": "2018-05-03T00:46:14.658353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.674395Z",
     "start_time": "2018-05-03T00:46:14.666373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow will be as follows: <br>\n",
    "First, we'll feed the neural network the training data, *train_image* and *train_labels*.\n",
    "The <span class=\"mark\">network will then learn to associate images and labels.</span> Finally, we'll ask the <span class=\"mark\">network to produce predictions for test_images</span>, and we'll verify whether these predictions match the labels from *test_labels.*\n",
    "\n",
    "Let's build the network-again, remember that you aren't expected to understand everything about this example yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.718011Z",
     "start_time": "2018-05-03T00:46:14.675398Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 The network architecture\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core building block of neural networks is the *<span class=\"mark\">layer</span>*, a data-processing module that you can think of as a filter for data. <span class=\"mark\">Some  data goes in, and it comes out in a more useful form.</span> Specifically, layers extract *representation* out of the data fed into them - hopefully, representations that are more meaningful for the problem at hand. Most of deep learning consists of chaining together simple layer that will implement a form of progressive *data distillation*. A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters -- the layers.\n",
    "\n",
    "Here, our network consists of a sequence of two *Dense* layers, which are densely connected (also called *fully connected*) neural layers. The second (and last) layer is a 10-way *softmax* layer. which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the network ready for training, we need to pick three more things, as part of the *compilation* step:\n",
    "\n",
    "- **A loss function** - How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "\n",
    "- **An optimizer** - The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "\n",
    "- **Metrics to monitor duting training and testing** - Here, we'll only care about accuracy (the fraction of the images that were correctly classified).\n",
    "\n",
    "The exact purpose of the loss function and the optimizer will be made clear throughout the next tow chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.755109Z",
     "start_time": "2018-05-03T00:46:14.719014Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.3 The compilation step\n",
    "network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we'll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images, for instance, were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float 32 array of shape (60000, 28 * 28) with values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.931077Z",
     "start_time": "2018-05-03T00:46:14.756112Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.4 Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:29:28.497546Z",
     "start_time": "2018-05-03T00:29:28.150625Z"
    }
   },
   "source": [
    "We also need to categorically encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:14.937093Z",
     "start_time": "2018-05-03T00:46:14.932080Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.5 Preparing the labels\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train the network, which in Keras is done via a call to the network's **fit** method - we fit the model to its training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:25.791368Z",
     "start_time": "2018-05-03T00:46:14.938096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2581 - acc: 0.9262\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1048 - acc: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0690 - acc: 0.9794\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0502 - acc: 0.9845\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0377 - acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146f0c18208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are displayed during training : **the loss of the network** over the training data, and **the accuracy of the network** over the training data.\n",
    "We quickly reach an accuracy of 0.989 (98.9%) on the training data. Now let's check that the model performs well on the test set, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T00:46:26.246579Z",
     "start_time": "2018-05-03T00:46:25.792371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/step\n",
      "test_acc :  0.9772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test-set accuracy turns out to be 97.7% -that's quite a bit lower thatn the training set accuracy. This gap between training accuracy and test accuracy is an example of **overfitting**: the fact that machine-learning models tend to perform worse on new data thatn on their training data.\n",
    "\n",
    "This concludes our first example - you just saw how you can build and train a neural network to classify handwritten digits in less than 20 lines of Python code. In the next chapter, I'll go into detail about every moving piece we just previewed and clarify what's going on behind the scences. You'll learn about tensors, the data-stroing objects going into the network; tensor operations, which layers are made of; and gradient descent, which allow your network to learn from its training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
