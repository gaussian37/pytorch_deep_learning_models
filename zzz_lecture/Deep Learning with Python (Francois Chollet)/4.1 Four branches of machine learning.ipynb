{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 4 covers\n",
    "- Forms of machine learning beyond classification and regression\n",
    "- Formal evaluation procedures for machine learning models\n",
    "- Preparing data for deep learning\n",
    "- Feature engineering\n",
    "- Tackling overfitting\n",
    "- The universal workflow for approaching machine learning problems\n",
    "\n",
    "After the threee practical examples in chapter 3, you should be starting to feel familiar with how to approach classification and regression problems using neural networks, and you've witnessed the central problem of machine learning: <span class=\"mark\">overfitting</span>. This chapter will formalize some of your new intuition into a solid conceptual framework for attacking and solving deep-learning problems. We'll consolidate all of these concepts - model evaluation, data preprocessing and feature engineering, and tackling overfitting - into a detailed seven-step workflow for tackling any machine-learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Four branches of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous examples, you've become familiar with three specific types of machine-learning problems: binary classification, multiclass classification, and scalar regression. All three are instances of supervised learning, where the goal is to learn the relationship between training inputs and training targets.\n",
    "\n",
    "Supervised learning is just the tip of the iceberg - machine learning is vast field with a complex subfield taxonomy. Machine-learning algorithms generally fall into four broad categries, described in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is by far the most common case. It consists of learning to map input data to known targets (also called annotations), given a set of examples (often annotated by humans). All four examples you've encountered in this book so far were canonical examples of supervised learning. Generally, almost all applications of deep learning that are in the spotlight these days belong in this category, such as optical character recognition, speech recognition, image classification , and language translation. <br> <br>\n",
    "Although supervised learning mostly consists of classification and regression, there are more exotic variants as well, including the following (with example):\n",
    "- Sequence generation - Given a picture, predict a caption describing it. Sequence generation can sometimes be reformulated as a series of classification problems (such as repeatedly predicting a word or token in a sequence).\n",
    "\n",
    "- Syntax tree prediction - Given a sentence, predict its decomposition into a syntax tree.\n",
    "\n",
    "- Object detection - Given a picture, draw a bounding box around certain objects inside the picture. This can also be expressed as a classification problem (given many candidate bounding boxes, classify the contents of each one) or as a joint classification and regression problem, where the bounding box coordinates are predicted via vector regression.\n",
    "\n",
    "- Image segmentation - Given a picture, draw a pixel - level mask on a specific object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This branch of machine learning consists of finding interesting transformations of the input data without the help of any targets, for the purposes of data visualization, data compression, or data denoising, or to better understand the correlations present in the data at hand. Unsupervised learning is the bread and butter of data analytics, and it's often a necessary steo in better understanding a dataset before attempting to solve a supervised-learning problem. Dimensionality reduction and clustering are well-known categories of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Self-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a specific instance of supervised learning, but it's different enough that that it deserves its own category. Self-supervised learning is supervised learning without human-annotated labels - you can think of it as supervised learning without any humans in the loop. There are still labels involved (because the learning has to be supervised by something), but they're generated from the input data, typically using a heuristic algorith.\n",
    "\n",
    "For instance, *autuencoders* are well-known instance of self-supervised learning, where the generated targets are the input, unmodified. In the same way, trying to predict the next frame in a video, given past frames, or the next word in a text, given previous words, are instances of self-supervised learning *(temporally supervised learning*, in this case : supervision comes from future input data). Note that the distinction between supervised, self-supervised, and unsupervised learning can be blurry sometimes - these categories are more of a continum without solid borders. Self-supervised learning can be reinterpreted as either supervised or unsupervised learning, depending on whether you pay attention to the learning mechanism or to the context of its application.\n",
    "\n",
    "In the book, we'll focus specifically on supervised learning, because it's by far the dominant form of deep learning today, with a wide range of industry application. We'll also take a briefer look at self-supervised learning in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Reinforcement learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Long overlooked, this branch of machine learning recently started to get a lot of attention after Google DeepMind successfully applied it to learning to play Atari games (and, later, learning to play Go at the highest level). In reinforcement learning, an *agent* receives information about its environment and learns to choose actions that will maximize some reward. For instance, a neural network that \"looks\" at a video game screen and outputs game actions in order to maximize its score can be trained via reinforcement learning.\n",
    "\n",
    "Currently, reinforcement learing is mostly a research area and hasn't yet had significant practical success betond games. In time, however, we expect to see reinforcement learning take over an increasingly large range of real-world applications: self-driving cars, robotics, resouce management, education, and so on. It's an idea whose time has come, or will come soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and regression glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and regression involve many specialized terms. You've'come across some of them in earlier examples, and you'll see more of them in future chapters. They have precise, machine-learning specific definitions, and you should be familiar with them:\n",
    "- Sample or input - One data point that goes into your model.\n",
    "- Prediction or output - What comes out of your model.\n",
    "- Target - The truth. What your model should ideally have predicted, according to an external source of data.\n",
    "- Prediction error or loss value - A measure of the distance between your model's prediction and the target.\n",
    "- Classes - A set of possible labels to choose from in a classification problem. For example, when classifying cat and dog pictures, \"dog\" and \"cat\" are the two classes.\n",
    "- Label - A specific instance of a class annotation in a classification problem. For instance, if picture #1234 is annotated as containing the class \"dog\", then \"dog\" is a label of picture #1234.\n",
    "- Ground-truth or annotations - All targets for a dataset, typically collected by humans.\n",
    "- Binary classification - A classification task where each input sample should be categorized into two exclusive categories.\n",
    "- Multilabel classification - A classification task where each input sample can be assigned multiple labels. For instance, a given image may contain both a cat and a dog and should be annotated both with the \"cat\" label and the \"dog\" label. The number of labels per image is usually variable.\n",
    "- Scalar regression - A task where the target is a continuous scalar value. Predicting house prices is a good example: the different target prices form a continuous space.\n",
    "- Vector regression - A task where the target is a set of continuous values: for example, a continuous vector. If your're doing regression against multiple values (such as the coordinates of a bounding box in an image), then you're doing vector regression.\n",
    "- Mini-batch or batch - A small set of samples (typically between 8 and 128) that are processed simultaneously by the model. The number of samples is often a power of 2, to facilitate memory allocation on GPU. When training, a mini-batch is used to compute a single gradient-descent update applied to the weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
