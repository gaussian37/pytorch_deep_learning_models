{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "37524291-7d8d-4ca8-a87d-50397b05b72f"
    }
   },
   "source": [
    "작성일 : 2018-01-10 15:01:10 <br>\n",
    "작성자 : Gauss Kim<br>\n",
    "참조 : [https://youtu.be/Boy3zHVrWB4](https://youtu.be/Boy3zHVrWB4)<br>\n",
    "참조 : [https://youtu.be/FWN3Sw5fFoM](https://youtu.be/FWN3Sw5fFoM)<br>\n",
    "참조 : [https://youtu.be/pg99FkXYK0M](https://youtu.be/pg99FkXYK0M)<br>\n",
    "참조 : [https://youtu.be/uNTtvxwfox0](https://youtu.be/uNTtvxwfox0)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:34:58.654418Z",
     "start_time": "2018-01-10T14:34:58.620299Z"
    },
    "nbpresent": {
     "id": "ad4c9994-d2c3-43a8-b353-32d879f3a5ab"
    }
   },
   "source": [
    "이번 강의에서는 Multi-Layer Perceptron에 대하여 알아보도록 하겠습니다.<br>\n",
    "먼저 어떻게 2개의 perceptron을 하나로 합치는 지 알아보도록 하겠습니다.\n",
    "\n",
    "![1](http://postfiles16.naver.net/MjAxODAxMDlfMjE5/MDAxNTE1NDkzNDgyMDQ3.Yyy4spzLJmbU_hJVuf2sAp0HrrJpBXOKVMHsPj0pSQQg.vfHOf98azlPsggN38OqlwB0bs2jPsfIeMI1sDBi6-kYg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000003494.png?type=w773)\n",
    "\n",
    "어떻게 위와 같이 Non-linear한 형태로 데이터를 분리하는 지 알아보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T14:37:50.188878Z",
     "start_time": "2018-01-10T14:37:50.156292Z"
    },
    "nbpresent": {
     "id": "9a22285e-d903-468e-a3d6-c807cbf6251d"
    }
   },
   "source": [
    "![2](http://postfiles10.naver.net/MjAxODAxMDlfMjUy/MDAxNTE1NDkzNTk2Njgx.7Yb_z3CdmFpWwfy3bVItM6v5EWZbFLgZJ1IJR3tTkZMg.0G_sc7Kx3aVz8il1ZzNqoV-ptLia7s6g0KVstk5Zhrgg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000018477.png?type=w773)\n",
    "\n",
    "2개의 linear 모델을 합쳐서 하나의 Non-linear 모델로 만들어 보겠습니다. 위 방법은 마치 model의 <font color='red'>사칙 연산</font> 같아 보이기도 합니다.<br>\n",
    "\"쉽게 말하면 1번 line과 2번 line을 합하면 3번 curve가 됩니다.\" 라고 설명하는 것과 같습니다. 이 연산을 수학적으로 자세히 알아보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ad15d1ef-fa9c-47bd-919b-6efae771d2bb"
    }
   },
   "source": [
    "![3](http://postfiles11.naver.net/MjAxODAxMDlfNTMg/MDAxNTE1NDk0MjkzOTkx.i8WMsgv9w0R_GjrcCxhe1R_EANCK-4br_OWmjoe5Ju0g.m86XWWRrnH1ilXBOeVLRU5_GPsg4AhPIs7o4DBKM2YEg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000051953.png?type=w773)\n",
    "\n",
    "### linear model은<span class=\"mark\">확률 공간</span> 입니다.<br>\n",
    "이것의 의미는 모든 점들은 blue가 될 확률값의 크기를 가집니다. 위 자료의 위쪽 linear model의 파란색 한 점은 파란색 영역에 있어서 0.7의 확률로 파란색 점이 됩니다. 아래쪽 linear model의 동일한 파란색 점 또한 파란색 영역에 있어서 0.8의 확률로 파란색 점이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](http://postfiles11.naver.net/MjAxODAxMDlfMjg3/MDAxNTE1NDk0MzQ3NzAx.P2qkK9LyJ7jqL11brgPanPZoDetWmmPEEHDhZwWFomcg.E-xviFjZEMXg6O4t9Hrl8t7nzKIDyDdqADF9tS4Ubrcg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000081229.png?type=w773)\n",
    "\n",
    "이 두가지 모델을 하나로 합치려면 가장 간단한 방법은 <span class=\"mark\">두 모델을 더하는 것</span>입니다.<br>\n",
    "각각의 모델에서 모든 점들의 확률은 [0, 1] 사이의 값을 가집니다. 하지만 여러 모델을 더하게 되면 확률이 1을 넘어가게 됩니다.<br>\n",
    "위에서 한 점은 ① 모델에서 $P(blue) = 0.7$, ② 모델에서 $P(blue) = 0.8$ 이었지만 ① + ② 에서는 1.5가 되어 1을 넘어버리는 문제가 발생합니다.<br> \n",
    "이 때 앞에서 사용한 sigmoid function을 이용하면 모든 입력 값에 대하여 [0, 1] 사이 범위 값으로 변형할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5](http://postfiles16.naver.net/MjAxODAxMDlfMTUx/MDAxNTE1NDk0ODIyMzk1.TG12ziK3k4yN9dnibGzJ2rhI57fuj-EKmc0MWXYQa6sg.pYk1CtFo2FI5VUUyvM87b1ALz0OKay_Ai5-q73MQmOkg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000098611.png?type=w773)\n",
    "\n",
    "따라서 sigmoid function을 적용하면 1.5 → 0.82 로 값을 조정할 수 있습니다.<br>\n",
    "따라서 두 model이 결합된 새로운 model에서는 위의 점이 blue가 될 확률은 0.82가 됩니다.<br>\n",
    "여기서 우리가 한 연산은 <span class=\"mark\">모든 각각의 점들에 대하여 확률 값을 구하고, 모두 더한 다음에, sigmoid 함수를 적용한 것</span>에 해당합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](http://postfiles13.naver.net/MjAxODAxMDlfMjg1/MDAxNTE1NDk1MTk5OTgy.nwHufDDDHPxg1v4mybOXBD36kR3R_NhvL-pxanbqGE4g.3bQ2RDVqiQF_13EV_x2qJyCT0drccJ6KwsPlHGHKK4og.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000125104.png?type=w773)\n",
    "\n",
    "만약 두 model을 합할 때 하나의 model에 좀 더 가중치를 주려고 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7](http://postfiles9.naver.net/MjAxODAxMDlfMjkw/MDAxNTE1NDk1Mjk5MjM2.cRtbBmIahFsx-U7kT29QCLbEjJKHu025qadIMXRmXnwg.GDZ-aEEf6bVEWtrjgN-NXgJ4aah2TCcmteJe43JWh-Ig.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000131672.png?type=w773)\n",
    "\n",
    "위의 model에 좀 더 큰 가중치를 적용하여 합하면 오른쪽과 같이 왼쪽-위의 model에 좀더 가깝게 합성이 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7](http://postfiles7.naver.net/MjAxODAxMDlfMzUg/MDAxNTE1NDk1NDI2ODAy.I97jeFFRFSLeBgW-HtlqBw-F7D62QNfBksGVctmct5Ag.AB_W6rDkLnNuhcGntwHzb9EBF9KbMknNgXvr7EeSTLcg.PNG.infoefficien/31-1._Neural_Network_Architecture.mp4_000182416.png?type=w773)\n",
    "\n",
    "예를 들어 위와 같이 각 <span class=\"mark\">모델에 가중치를 적용</span>해 보겠습니다.<br>\n",
    "첫번째 모델에 7배의 가중치를 주고 아래 모델에 5배의 가중치를 준 다음 합쳐보겠습니다. 그리고 bias를 -6 적용하여 보겠습니다. 우리가 계속 다루었던 파란 점을 기준으로 보면 $7 * 0.7 + 5 * 0.8 - 6 =2.9$가 되고 이 값에 sigmoid를 적용하여 0.95의 값을 최종적으로 얻었습니다.\n",
    "<span class=\"mark\">두 model의 가중치 합을 적용한 최종 모델은 오른쪽의 curve</span>와 같습니다. \n",
    "최종적으로 curve의 형태를 보면 왼쪽 2개의 model을 결합한 것 처럼 보입니다. 이것은 단지 우연히 아닙니다.\n",
    "우리는 위와 같이 <span class=\"mark\">linear model을 결합하는 방법으로 복잡한 model을 만들어 낼 것</span>입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8](http://postfiles8.naver.net/MjAxODAxMDlfNDIg/MDAxNTE1NDk2MDg0MzQ3.L0InvNWVHYsrDNaUASCB9bhIHPjEUs7kB95pdYyuCtUg.eAARvNnnp2jpp6pOcxoMxuqZ7Kz4R2S4mYMiAa9y5g8g.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000022639.png?type=w773)\n",
    "\n",
    "위에서 두 model을 합성한 것은 마치 neuron에 weight를 곱하고 bias를 더한 형태와 동일 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9](http://postfiles9.naver.net/MjAxODAxMDlfMTM3/MDAxNTE1NDk2MjAyNDcy.KK-s-wOlE2XX887wUkgqO_LTEvKl4syOyZ_a2Oxm6gIg.jnHis3XLKGsZeohnafiN6NU0QyDEBUkpy9XIzPmEz50g.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000051095.png?type=w773)\n",
    "\n",
    "좀 더 구체적으로 예를 보면 첫 번째 모델은 $5x_{1} - 2x_{2} + 8 = 0$의 linear 모델이고 두 번째 모델은 $7x_{1} - 3x_{2} - 1 = 0$의 linear 모델입니다.<br> 각 model을 perceptron으로 표현하면 오른쪽과 같이 <span class=\"mark\">neuron, weight, bias로 표현 가능</span> 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![10](http://postfiles8.naver.net/MjAxODAxMDlfMTQy/MDAxNTE1NDk2NjQ5NTQ3.KwQN5AvNLW6ERjA00AH7SLiGfwHh0iZhLmfcga8aLXQg.TbbogRkcPNiGvd2_4MjCKeFs5VtRP6Da--OLjI9zMLkg.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000070182.png?type=w773)\n",
    "\n",
    "이제 두 model을 결합해 보곘습니다. <span class=\"mark\">두 model을 결합하는 것은 두 perceptron을 결합하는 것과 동일</span>합니다. 각 perceptron의 결과에 weight를 곱하고 bias를 더하면 위에서 model을 결합한 것과 동일합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![11](http://postfiles9.naver.net/MjAxODAxMDlfMjQz/MDAxNTE1NDk2NzcwMDM1.L_03gwRSSij4LOK98bvHWAjrliHrPVGTytlgvd9vvM4g.WXVaiF_3wKnZDbeaWh3pOIBWDaWszGusU_LwaGZxE3gg.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000074568.png?type=w773)\n",
    "\n",
    "Perceptron을 좀 더 깔끔하게 변형하면 위와 같이 변형할 수 있습니다. $x_{1}, x_{2}$입력 값은 각 model의 공통 인자 이므로 묶어서 하나로 표현할 수 있고 weight는 간선에 bias는 노드로 표현하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![12](http://postfiles5.naver.net/MjAxODAxMDlfMjEg/MDAxNTE1NDk3MzMzNjY2.YbMLGhcEEBSvCSZMfjRjaHV5Sq986TtvuTwGEbfNRQUg.sGNzZaBiGrCjcIxk5gecml85KraDuCsfTVhNMAinuj8g.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000094911.png?type=w773)\n",
    "\n",
    "이제 왼쪽과 같은 Neural Network를 봤을 때, Non-linear boundary가 어떻게 정의될 지 생각해 봐야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![13](http://postfiles5.naver.net/MjAxODAxMDlfNjEg/MDAxNTE1NDk4MDY0MjU1.3S-2_aP3y7o5BzXfs-vfKj35A0CzlJN6TNAQXEuIIf0g.OK17FwccGa8l2XKT-_-dqbRsfa0MVduzjikIeH1ovpQg.PNG.infoefficien/31-2._Neural_Network_Architecture.mp4_000108621.png?type=w773)\n",
    "\n",
    "이제 Neural network의 perceptron을 좀 더 일반적으로 표현해 보겠습니다. 오른쪽 개선된 표현법에서는 bias가 하나의 독립된 node로 분리 되었습니다. -8을 표현하려면 bias 1에 weight 8을 곱하여 -8로 만듭니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T15:41:00.134052Z",
     "start_time": "2018-01-10T15:41:00.128035Z"
    }
   },
   "source": [
    " **Multiple Layer를 구성하는 방법**에 대하여 알아보겠습니다.\n",
    "- 더 많은 인풋 노드와 hidden layer, output layer를 구성\n",
    "- 더 많은 layer를 적용\n",
    "\n",
    "![14](http://postfiles13.naver.net/MjAxODAxMDlfMTU4/MDAxNTE1NDk5MjY2NDQz.ggpKTYp4rpGB5wu9QmtsZJLa94b_5wXOiACnkzfdxK0g.H5E71961fqiKXpJNyJ_gIWsZ5Kdf7HWVJ4TFUANFuuwg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000004074.png?type=w773)\n",
    "\n",
    "Neural Network는 layer 마다 특징을 가집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![15](http://postfiles10.naver.net/MjAxODAxMDlfMjAg/MDAxNTE1NDk5NTA4NDA5.Dn2GdEiRDATIgUbyoj-uo2jd5da_6rsj8EzMgTHYeAwg.nLrlcz9Pxgl_NO6WXE6UHhSZyDke2tMlHjyGuJh-aFEg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000008874.png?type=w773)\n",
    "\n",
    "첫 번째 layer는 <span class=\"mark\">Input layer</span> 입니다. 이 layer는 Input을 가지고 여기서는 $x_{1}, x_{2}$ 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![16](http://postfiles4.naver.net/MjAxODAxMDlfMTc3/MDAxNTE1NDk5NjQwNzk4.Tk2DrkEw1slSqVTpzBSUm3PDKyLPVlxCTdQUljnT2nog.TNykBIlQVCgkp2X6YL7u7pkDUHle0EUzrw9fiTRxtHUg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000014504.png?type=w773)\n",
    "\n",
    "다음으로 사용되는 layer는 <span class=\"mark\">hidden layer</span>로 input layer를 이용하여 linear model을 구성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![17](http://postfiles13.naver.net/MjAxODAxMDlfNTMg/MDAxNTE1NDk5NzQ0MDU4.7SqvAJWSGig4l9I2TDzYqxxc00JEvBk2bQBV1HoS7zcg.i8YsTeMCgIVqpxbanvIU5xDOEbu84EjyRVn0eJsXh90g.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000021338.png?type=w773)\n",
    "\n",
    "마지막 layer는 <span class=\"mark\">output layer</span>로 linear model들이 최종적으로 결합되어 non-linear model을 만듭니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![18](http://postfiles11.naver.net/MjAxODAxMDlfMjMg/MDAxNTE1NTAwMzI2MDQ1.87dCvree1hp9xJUTA_qllfw490NmyqrhFg0HyNlubHYg._lianm7JETT9oAbgQoNR4Orx8IpDjG6NrH_MuoUttcsg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000032811.png?type=w773)\n",
    "\n",
    "만약 Input node가 늘어난다면 어떤 영향이 있는지 알아봅시다. 위의 Neural Network에서는 3개의 Input을 가집니다. 즉, 2차원에서 3차원으로 확장시킨 것이라 생각하시면 됩니다.<br> \n",
    "Input layer에서 값을 받아 hidden layer에서는 3차원의 linear한 평면을 만들어 냅니다.<br>\n",
    "그리고 output layer에서는 hidden layer를 결합하여 non-linear한 곡면 boundary를 만들어 냅니다.<br>\n",
    "일반적으로 <span class=\"mark\">n개 input을 가지면 n-dimension</span>이 된다고 생각하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![17](http://postfiles11.naver.net/MjAxODAxMDlfMTMg/MDAxNTE1NTAwNzg2OTc5.Y_UH3eP3lu8Ae8uZNi8L5RUcdzgF-K1ztWDSAmk9J5Yg.jgl-DLuro_XHy0G3PUcqzSPuJbuI0RgKGEIzbKjtJ0Qg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000080080.png?type=w773)\n",
    "\n",
    "### Output Layer의 노드 갯수를 더 많이 가지는 경우\n",
    "\n",
    "만약에 output layer가 더 많은 node 값을 가진다면 어떻게 될까요? 이 경우에는 <span class=\"mark\">multi-class classification model</span>을 가집니다.<br>\n",
    "이 때 output layer는 예를 들어서 이미지를 CAT,DOG, BIRD 등으로 구분지어 줍니다. 그러면 output layer의 각각의 노드는 각각의 class에 대한 score를 매깁니다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![19](http://postfiles16.naver.net/MjAxODAxMDlfMTU3/MDAxNTE1NTAxMjY4MzM1.-EJJdI_o5RLGoN-W8w4y3aTrisGmq8PEzUZ3QhwAYIgg.OOS8XMt-hsZIGyCVOACP6SrFG-7JAPry9qb2lFfwNtUg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000101434.png?type=w773)\n",
    "\n",
    "### Layer 를 더 깊게 만드는 경우\n",
    "\n",
    "그러면 더 많은 layer를 가지게 되면 어떻게 될까요? 이렇게 2개 이상의 hidden layer를 가지면 deep neural network라고 합니다.<br>\n",
    "첫 번째 hidden layer에서는 linear model을 만들었고 linear model의 결합으로 두번째 hidden layer에서 non linear model이 만들어 졌습니다. 이 때 만들어진 non linear model을 이용하여 <span class=\"mark\">좀 더 복잡한 non linear model</span>을 output layer에서 만들어 냈습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20](http://postfiles11.naver.net/MjAxODAxMDlfMjk3/MDAxNTE1NTAxNDE4OTcz.28tyrXIu0tD0c7QrwpPvBUf-vOO-nWIgONM_UJmSazcg.McqQUuGvS3qQbUfyxrpmXUjIajoNRR26SI4hhcPpHAQg.PNG.infoefficien/31-3._Neural_Network_Architecture.mp4_000118297.png?type=w773)\n",
    "\n",
    "이렇게 <span class=\"mark\">layer를 깊게 쌓으면 쌓을수록 좀 더 복잡한 non linear model을 만들 수 있습니다</span>. 이것이 Neural network가 동작하는 방법입니다. \n",
    "n-dimensional 공간에 non-linear boundary를 이용하여 다양한 classification을 하는 원리는 위와 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification \n",
    "\n",
    "![21](http://postfiles12.naver.net/MjAxODAxMDlfNDIg/MDAxNTE1NTAxODc5ODgz.Kym8jO0vqfL9OVKeIPtx0dnrsaCOEiQiC38LYxLmrsMg.Lia2Ou21khvqI50m-IPMsbxt96q8Y9cozVBMlEFHiekg.PNG.infoefficien/31-4._Neural_Network_Architecture.mp4_000043963.png?type=w773)\n",
    "\n",
    "Neural network를 이용하여 이미지 duck, beaver, walrus를 구분한다고 가정합시다.<br>\n",
    "아주 간단하게 생각하면 각각의 이미지에 대하여 Neural network를 구성한 후 softmax를 적용하여 확률을 구하면 될 것 으로 판단 됩니다. 하지만 이것은 매우 비용이 큰 방법입니다. <span class=\"mark\">하나의 Neural Network를 이용하여 이미지를 분류</span>하고 마지막 output layer에서 어떤 이미지가 가장 확률이 높은지 이용하면 충분해 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![22](http://postfiles3.naver.net/MjAxODAxMDlfNTEg/MDAxNTE1NTAyMDI0MzY1.MZASw-HDYd6M--RGX6lwBAzvMC4iQLzCtKlcX0U2-ggg.Yk2ajucllnuVnafMgCPdA5JWS8Mg4CYBHC2_FdDZROQg.PNG.infoefficien/31-4._Neural_Network_Architecture.mp4_000069881.png?type=w773)\n",
    "\n",
    "이미지 분류에 관해서는 CNN에서 자세히 다룰 예정입니다. 이런 Neural Network를 구성하려면 <span class=\"mark\">output layer에 분류 이미지 갯수 만큼 노드를 추가하고 output layer 각각의 node는 대응되는 각각의 이미지로 input이 분류될 확률을 반환</span>해야 합니다.<br>\n",
    "이 점수를 이용하여 Softmax 함수를 적용하면 전체 합이 1인 확률을 구할 수 있습니다. 이 방법이 Neural network를 이용하여 Multi-class classification을 하는 방법 입니다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "031ad166-2172-459b-9032-25a67d3322af": {
     "id": "031ad166-2172-459b-9032-25a67d3322af",
     "layout": "manual",
     "prev": "9e1715cd-ae57-4e02-92db-f74c760ec05c",
     "regions": {
      "4071a2a2-1f44-4c8a-888d-e8ff81d8014c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad15d1ef-fa9c-47bd-919b-6efae771d2bb",
        "part": "source"
       },
       "id": "4071a2a2-1f44-4c8a-888d-e8ff81d8014c"
      }
     }
    },
    "623e197d-e4c4-4bf4-b10a-c9505faf8d9f": {
     "id": "623e197d-e4c4-4bf4-b10a-c9505faf8d9f",
     "prev": null,
     "regions": {
      "01683bbd-c40e-4267-90d6-f4a5943cbcfb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad4c9994-d2c3-43a8-b353-32d879f3a5ab",
        "part": "whole"
       },
       "id": "01683bbd-c40e-4267-90d6-f4a5943cbcfb"
      }
     }
    },
    "9e1715cd-ae57-4e02-92db-f74c760ec05c": {
     "id": "9e1715cd-ae57-4e02-92db-f74c760ec05c",
     "prev": "623e197d-e4c4-4bf4-b10a-c9505faf8d9f",
     "regions": {
      "74766b64-959e-47ef-bed7-7b9c32ec524c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a22285e-d903-468e-a3d6-c807cbf6251d",
        "part": "source"
       },
       "id": "74766b64-959e-47ef-bed7-7b9c32ec524c"
      }
     }
    },
    "e6fe1b65-ac5f-4ef0-a5c0-ec5aedec3d4b": {
     "id": "e6fe1b65-ac5f-4ef0-a5c0-ec5aedec3d4b",
     "prev": "031ad166-2172-459b-9032-25a67d3322af",
     "regions": {
      "3182b268-5176-4a1f-aac0-7ff9aa0d2df4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ad15d1ef-fa9c-47bd-919b-6efae771d2bb",
        "part": "whole"
       },
       "id": "3182b268-5176-4a1f-aac0-7ff9aa0d2df4"
      }
     }
    }
   },
   "themes": {
    "default": "add44077-5faf-4134-a1bb-2f9a6b8532a5",
    "theme": {
     "add44077-5faf-4134-a1bb-2f9a6b8532a5": {
      "id": "add44077-5faf-4134-a1bb-2f9a6b8532a5",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     },
     "c330c806-f0c3-4d3b-8782-53dfe9e0dc81": {
      "id": "c330c806-f0c3-4d3b-8782-53dfe9e0dc81",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
