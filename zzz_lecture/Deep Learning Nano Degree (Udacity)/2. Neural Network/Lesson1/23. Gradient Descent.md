참조 : [https://youtu.be/26_dnS0r2jc](https://youtu.be/26_dnS0r2jc)

![1](http://postfiles11.naver.net/MjAxODAxMDdfMTA3/MDAxNTE1MzA5MzM5MjQ4.d2XRcaLOwBN9o1R-nqy-o7MGsu5uISJ4-SDqPxxOAOog.CgwVSSWEXN1l5kXCcjZGgI-Lg5m-LqTyvJwLeJnjKtcg.PNG.infoefficien/23._Gradient_Descent.mp4_000022137.png?type=w773)

Gradient Descent에 대하여 좀 더 자세하게 알아보도록 하겠습니다.<br>
Error function은 weight에 관한 함수이고 그래프화 하면 위 처럼 표현할 수 있습니다.

현재 MATH-ER-HONR 산의 어느 지점에 서있고 우리의 목적은 아래로 내려가는 것입니다. (참고로 Matherhorn은 알프스 봉우리 중 하나입니다.)<br>
Error function 에서의 입력은 W1, W2이고 이에 따른 출력값은 Error와 같습니다.

![2](http://postfiles16.naver.net/MjAxODAxMDdfMTI3/MDAxNTE1MzEwMTk5NzI5.pdQreglvAhTfK0gWJgZ_7gnF06L3HgNIohTJhlDEPwwg.Fu7P2gPNrLdCTD_Mq-b-uw3KrtsUVKzfJ3SmejK4efkg.PNG.infoefficien/23._Gradient_Descent.mp4_000049424.png?type=w773) 

Error에 대한 gradient는 Error에 대한 W1, W2 각각의 편미분값의 벡터 합으로 나타나 집니다.<br>
gradient는 우리가 움직일 방향을 말해주기 때문에 ∇E, -∇E방향에 따라 Error function의 값을 증가 또는 감소 시킬 수 있습니다.

![3](http://postfiles15.naver.net/MjAxODAxMDdfNDkg/MDAxNTE1MzEwNjc0MDYw.xIDlseevFwSxlEfuGYTQRKgdce8FG-8Ed8TetwNTtTgg.I1FKXpU9jCueHN5wKlVFrL4LDr7ZF05SuNM1quoJgxAg.PNG.infoefficien/23._Gradient_Descent.mp4_000056541.png?type=w773) 

어떤 지점에 서 있을 때, -∇E(negative of the gradient of the Error function)을 적용해 보겠습니다. 

![4](http://postfiles14.naver.net/MjAxODAxMDdfNDcg/MDAxNTE1MzEwOTY1Njg1.nvo1BkkXwcw_KVJQ1Vz6VQTBZWGo42MNnCCLQhyPMc0g.1LG9zpZzNY2oMKhN52R76At0bEkarHclCsXpfRgXb_Mg.PNG.infoefficien/23._Gradient_Descent.mp4_000060128.png?type=w773)

-∇E을 적용하면 Error function을 줄일 수 있습니다.(좀 더 아래로 내려왔습니다.)<br>
-∇E을 계속 적용하면 Error function을 지속적으로 줄일 수 있습니다. (계속 아래로 내려올 수 있습니다.)

![5](http://postfiles1.naver.net/MjAxODAxMDdfMjIw/MDAxNTE1MzExMDY2NTQy.wWBOySk9vPmaOSYTMi0BCy8gZzSetqtFCmh_5wp6FxIg.ub3VywstUzIHIsfjpPnLOUGMqn2gmYtiPqnu9Lv7194g.PNG.infoefficien/23._Gradient_Descent.mp4_000068551.png?type=w773)

결국에는 지면까지 내려 올 수 있게 됩니다. 이렇게 지면에 내려오는 방법을 계산해 보도록 하겠습니다.

![6](http://postfiles9.naver.net/MjAxODAxMDdfMjU4/MDAxNTE1MzExMTkzMzA0.RQuNkPQ_3NMMZls-l7AgyCF0Rth_wwQ1gn4lCEIKvT4g.kNmw-Tx6ngyh-JH7rLODo6vksfmFgMN6As8a8b-yU00g.PNG.infoefficien/23._Gradient_Descent.mp4_000082470.png?type=w773)

첫번째 Prediction은 y = σ(Wx+b) 라고 가정합시다. (σ = sigmoid)<br>
이 Prediction은 결과가 나쁘다고 가정하여 어떻게 Error function을 줄이는지 봅시다.

![7](http://postfiles5.naver.net/MjAxODAxMDdfMjU4/MDAxNTE1MzExMzI4OTg5.PJs6ncr2tgJiJJ4kMunAn9pbZvxz_oXMwNQRnzChviAg.rdRlBPSF6sB2cj1QuCLGOLdjdqsnMgZ_WKDzNkSY__sg.PNG.infoefficien/23._Gradient_Descent.mp4_000087806.png?type=w773)

먼저 Prediction은 y = σ(W1x1 + ... + Wnxn +b) 입니다.

![8](http://postfiles12.naver.net/MjAxODAxMDdfMTk1/MDAxNTE1MzExMzkyMzU1.ZYw5DU8QPReom8uLJXuVGK9N07VxF8vjH1cRvlwL-Ksg.04FlbH8zowESqTSdzIRWduhDnCagAxs1rXQT36t2Ytcg.PNG.infoefficien/23._Gradient_Descent.mp4_000097919.png?type=w773)

여기서 중요한 것은 Error function의 gradient 입니다. gradient를 계산하면 ∇E = (∂E/∂w1, ... , ∂E/∂wn , ∂E/∂b) 입니다.<br> ∇E 는 각각의 weight와 bias에 의한 편미분 값으로 구성된 vector 입니다. 

![9](http://postfiles13.naver.net/MjAxODAxMDdfMjA2/MDAxNTE1MzExOTY0Nzkz.wRbt0UD0yhYm05iVb1NZ4ljaGMe523pUoG-yOv2Edekg.lJdhdrzMtua7AVspKUde8Mc72V-7JUwORrHdjr66HfEg.PNG.infoefficien/23._Gradient_Descent.mp4_000121511.png?type=w773)

다음으로 -∇E(negative of gradient) 방향으로 이동해 보겠습니다. <br>
이 때, 많은 변화를 한번에 적용하지 않기 위해 learning rate α = 0.1을 지정하여 ∇E와 곱해줍니다. 

![10](http://postfiles5.naver.net/MjAxODAxMDdfMTM4/MDAxNTE1MzEyMDM1NDg5.HQIytMCbMPxIzssXidjyuHKYIcpCfrrA1RoUowRb8zYg.qmzNIkVA60SHJeU0J_IB69uUREtllfXpG-dex8hl4DUg.PNG.infoefficien/23._Gradient_Descent.mp4_000130654.png?type=w773)

따라서 위의 그래프와 같이 -α∇E의 방향과 크기 만큼 이동합니다. 

![11](http://postfiles7.naver.net/MjAxODAxMDdfMTAg/MDAxNTE1MzEzNTc3NjE4.ZZ25fkF1gm6irv1M1KB0wFbd3r5Cp_VhysVyCvyEmXQg.OmwnPFzS_x7fJuVsOSKMJOv_7PTmvof12Fl3mrr4z28g.PNG.infoefficien/23._Gradient_Descent.mp4_000135480.png?type=w773)

따라서 ∇E(각 w_i에 대하여 편미분한 벡터)와 α를 이용하여 weight인 w를 업데이트 하면 w_i' ← w_i - α * (∂E / ∂W_i) 가 됩니다. 

![12](http://postfiles12.naver.net/MjAxODAxMDdfMjQ1/MDAxNTE1MzE0NTA2MTIy.omcJ4Hovq0M5W7831Kg9BMdT_bRiiIc15h_D7r9tW48g.gw0PbCpctVPgItXmRuTYF0Q7VXpowh7yY4A6jtYTIKYg.PNG.infoefficien/23._Gradient_Descent.mp4_000155778.png?type=w773)

그리고 bias 또한 동일한 방법으로 업데이트가 됩니다. <br>
w'와 b'을 이용하여 E(W', b')를 얻으면 E(W, b)에 비하여 Error 값이 줄어들게 됩니다.

![13](http://postfiles8.naver.net/MjAxODAxMDdfMTU1/MDAxNTE1MzE1NTMyOTU4.XvYy79LE46bU137nOyLb5kcbi6KFN2pn7_1FFlzLqcMg.2Alwkl24p3HilR1yDbGsrVCa71ZuHISJmCOsyKedESsg.PNG.infoefficien/23._Gradient_Descent.mp4_000169207.png?type=w773)

위와 같은 방식으로 W,b를 업데이트 하면 Error를 줄일 수 있습니다.

이 때까지 Error function을 최소화 하려면 편미분을 적용해야 함을 배웠습니다. 그러면 예를 들어서 실제 계산을 어떻게 하는지 확인해 보겠습니다. 

위에서 사용한 sigmoid function은 미분 결과가 아주 간단하여 사용하기 편리합니다.<br>
σ​′​​(x)=σ(x)(1−σ(x)) 가 됩니다.

![14](http://postfiles7.naver.net/MjAxODAxMDdfMjk4/MDAxNTE1MzE2ODU1OTU1.BrLfCahYn_elnrbQxV2AodXKb3Q_hpFGsZyuYC661WQg.yKuHccSeEO3I173-cYuu91csFO7m8YX9RBA6hTW68jcg.PNG.infoefficien/image.png?type=w773)

m개의 point인 x(1), x(2), ..., x(m)이 있다고 가정합시다.<br>

![15](http://postfiles3.naver.net/MjAxODAxMDdfMjg1/MDAxNTE1MzE3MDU3MzA2.BvzGs8cQ_UvC1LyLLv16jQfRMNsMmUhR3GZdFwOqDlUg.otuDQbAPslK62pJBXFe1svXVoBHuNGzR_EvvgqNduE4g.PNG.infoefficien/image.png?type=w773)

Binary classification의 Error function식은 위와 같습니다.

![16](http://postfiles6.naver.net/MjAxODAxMDdfMjg5/MDAxNTE1MzE3MTU4MDkz.EcDt4SjG_JbnPserd1119oZkk79Pt2QDL4s-00vQ88sg.lXmxFqTKmzsUgVtSBAGUH_E9j9Wmh9JH1w-pQPGfXb8g.PNG.infoefficien/image.png?type=w773)

prediction 은 위와 같습니다.<br>
다시 한번 정리하면, 우리의 목표는 E를 최소화 하는 것입니다.<br> 
E를 최소화 하기 위하여 입력값 x =(x​1​​,…,x​n​​)가 연산될 파라미터에 대한 E의 gradient를 구해야 했습니다. 즉, E의 gradient를 구하기 위해서 파라미터 weight와 bias에 대하여 편미분을 해야합니다.

![17](http://postfiles7.naver.net/MjAxODAxMDdfMTc5/MDAxNTE1MzE5MTY1NTA1.NnNyl_JgnzE_V5qBowkaEhxXqc89iPO6Xg-MZubkKsog.vjv3FpzvFF_QN1Ypex7wScpktzu18zOw5xE3CBXKr2Yg.PNG.infoefficien/image.png?type=w773)

계산을 좀 더 단순하게 하기 위하여 각각의 point에서의 error를 계산해보고, 전체 error로 확장해 보겠습니다.

![18](http://postfiles2.naver.net/MjAxODAxMDdfMjQ2/MDAxNTE1MzE5Njg5MTM2.DPl15eQcvnGaC96iPL8QLEtDsTG7Jku82-YtVFqfhtkg.B85PLLb9YEj3lYyuPDYzBsUDhz9S0PXth4E8ory59jcg.PNG.infoefficien/image.png?type=w773)

전체 Error function 값이 아닌 한 점에 대한 Error function 값은 위와 같습니다. (Σ 및 average 연산이 없음) <br>
각각의 weight에 대하여 편미분을 계산해 보려면 먼저, (∂y^ / ∂w_j)를 계산해 봅니다. 

![19](http://postfiles7.naver.net/MjAxODAxMDdfMjIy/MDAxNTE1MzIwMDcwNDg2.XTZyZvpMFQFLh6jwZMnG4-jT8emWCixI2AbTFHVYBtYg.IOhrDq7_L9pC2xeOBWj82hT07FCSx3ZsUTwUTG2Dz7Mg.PNG.infoefficien/image.png?type=w773) 이므로

![20](http://postfiles14.naver.net/MjAxODAxMDdfMTcw/MDAxNTE1MzIwMDg4MzMw.0ttZi2FUrcNPlrmeI0JliNaLLEq_TwZ6lsYr601g2qUg.pdCbX0FvgV3K0jpwxrL0il8Oi9uODE8wTB4aIlweUY8g.PNG.infoefficien/image.png?type=w773)가 됩니다.

이제 다음으로 point x에서 각각의 W에 대한 Error E의 편미분을 구해보겠습니다.<br>
(Error function의 원래 형태는 average를 적용한 것으로 (1/m)Σ 를 적용하였으나, 편의상 생략하였습니다.)

![21](http://postfiles5.naver.net/MjAxODAxMDdfMTk1/MDAxNTE1MzIwMzE0OTE4.XAjVa9ayc-qRVdU3KC4NTtGyakTl7dR0oteNaPevFKYg.dTMRohvsUMDfMaECQPmnZO-oBjkmGJFdc7JBdzUbQTsg.PNG.infoefficien/image.png?type=w773)



동일한 방법을 이용하면 ![22](http://postfiles11.naver.net/MjAxODAxMDdfMTAz/MDAxNTE1MzIwMzQ3MjQw.tcVefY1qME0WOiwfBPEUitnZwaJLFAtAgxb2AnbQlk8g.uFpX2cUfxzZgtqqlE-KvhMwjqudjYf_uzlsa-th5B0Ug.PNG.infoefficien/image.png?type=w773)임을 구할 수 있습니다.

이 결과는 상당히 시사점이 있습니다. 포인트 (x1, ..., xn) , 라벨 y, 확률(prediction) y^에 대하여 Error function의 gradient는 (−(y−​y​^​​)x​1​​,⋯, −(y−​y​^​​)x​n​​, −(y−​y​^​​)) 가 됩니다. 

![23](http://postfiles13.naver.net/MjAxODAxMDdfMjUz/MDAxNTE1MzIwNTMwNDk4.vIknGM1l2JI_V9bqoxoocO7Ihd9qYFkTnVigUb2mkAcg.EK9HFN_WnKZaf30LdT-RYZJPUN4NdFVVfXnBDqZtuwkg.PNG.infoefficien/image.png?type=w773)

즉 모든 gradient를 벡터화 해서 표현하면 ∇E는 위와 같습니다.<br>
∇E 식을 자세히 보면 포인트 값에 스칼라 값을 곱한 것이 ∇E가 됩니다. 여기서 스칼라 값은 label과 prediction의 차이 입니다.<br> 이것이 갖는 의미는 다음과 같습니다.

① label과 prediction의 값이 가까울수록 작은 gradient 값을 가집니다.<br>
② label과 prediction의 값이 멀수록 큰 gradient 값을 가집니다.<br>
ex) label  = 1 일때, prediction이 1에 가까워야 즉, 실제 발생할 확률이 높아야 gradient가 작아집니다. label = 0일때, prediction이 0에 가까워야 즉 실제 발생할 확률이 낮아야 gradient가 작아집니다.

작은 gradient 값의 의미는 포인트 값을 조금 변경할 것이고 큰 gradient 값의 의미는 포인트 값을 크게 변경할 것입니다.

**Gradient Descent Step은 따라서 다음과 같은 방식으로 이루어 집니다.**


- weight에 대한 업데이트를 하면 아래와 같습니다.

![24](http://postfiles15.naver.net/MjAxODAxMDdfMTM2/MDAxNTE1MzIxNTE4OTI2.VDS-4B0h3-A4ANHGd5CtWQyhd1tp1SkqIWV3MaS07Sog.J40Jkkj_wozK76BSNIhe3528L2beZwml7gaHKTpEor0g.PNG.infoefficien/image.png?type=w773)

![25](http://postfiles13.naver.net/MjAxODAxMDdfMzgg/MDAxNTE1MzIxNzI0NzMz.ThQAAszWugumQbPs2nb0iDYFhJ2_QUVeSKvASWTywlAg.HLppOzvT6K9EPU6yiWeENVLT4mU_Ehqpwv9nUZ0V3yAg.PNG.infoefficien/image.png?type=w773)

- bias에 대한 업데이트를 하면 아래와 같습니다.

![26](http://postfiles2.naver.net/MjAxODAxMDdfMjg3/MDAxNTE1MzIxNzQxMDUz.bL_uHRt-GjxpJN8U_WF4K3q5ihrwj3icWEGBCL1bt6Yg.nWYLcgMs2lTK4p849GWJfHT_BHKRyG9yfk7C_3e3hXMg.PNG.infoefficien/image.png?type=w773)

※ 위에서 생략한 (1/m)Σ 를 실제 적용하면 α → α * (1/m)이 되어야 하지만 이 값 또한 다시 α로 표현 가능합니다.