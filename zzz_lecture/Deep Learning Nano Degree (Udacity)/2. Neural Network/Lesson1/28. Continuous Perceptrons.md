참조 : [https://youtu.be/07-JJ-aGEfM](https://youtu.be/07-JJ-aGEfM)

![1](http://postfiles3.naver.net/MjAxODAxMDlfMjI0/MDAxNTE1NDc4NTgxNDgy.wo878O6l3j2t08r7n3d0s0D0LrjjbaB3KryUtGl1vsIg.lqVqBdxwb_8zxmr71kNa2GBkJpm6qemIT9zaDzKzYJQg.PNG.infoefficien/28._Continuous_Perceptrons.mp4_000005884.png?type=w773)

이번 강의에서는 앞에서 배운 내용을 잠시 복습해 보겠습니다. 위의 점들과 같은 데이터 분포를 가지고 있고 linear model이 위와 같이 2x1 + 7x2 -4 = 0과 같다면<br>
Positive region(blue region)은 Positive(blue)일 확률이 높고 Negative region(red region)은 Negative(red)일 확률이 높습니다. 

![2](http://postfiles12.naver.net/MjAxODAxMDlfODAg/MDAxNTE1NDc4ODM1NTgx.6obmV00yO_LIOdJ4p5BW0ezi08jH2bI9q6lsKgdGg0kg.R9zhvSGUps8tPe3bMpyrK5i5va3owYlRHQav20r99wcg.PNG.infoefficien/28._Continuous_Perceptrons.mp4_000035659.png?type=w773)

이 모델을 Perceptron으로 표현하면 오른쪽과 같이 weihgt와 bias의 선형 결합으로 표현할 수 있습니다. 

![3](http://postfiles2.naver.net/MjAxODAxMDlfMTcg/MDAxNTE1NDc5MDA1MDYx.uP2hRhv236FjeVPiipkfhYts7H-JqGQauL0QCHejdPwg.AMCqlP86_vCs3g6uSpCRcI__32gf99GOt2VV4yiTn6Ug.PNG.infoefficien/28._Continuous_Perceptrons.mp4_000046131.png?type=w773)

따라서 Percptron의 역할은 포인트(x1, x2)를 받아서 graph에 나타내고 포인트가 파란색일 확률을 반환합니다. 위 예에서의 확률 값은 0.9 입니다.

![4](http://postfiles3.naver.net/MjAxODAxMDlfMjky/MDAxNTE1NDc5MDUzMTgw.5QB99VW15Zw7T6MOG9J_zzuC5oX25YzfEALBX3bhBbwg.vS55MLfLgCqHlgz7f6MCy1Oce-9W3E8VjhFB4jYFwokg.PNG.infoefficien/28._Continuous_Perceptrons.mp4_000053386.png?type=w773)

이 과정을 보면 Perceptron은 Neuron을 모방한 것처럼 보입니다. 왜냐하면 Neuron은 Nervous impulse를 입력으로 받고 결과를 반환하는 방법이 Perceptron과 유사하기 때문입니다.