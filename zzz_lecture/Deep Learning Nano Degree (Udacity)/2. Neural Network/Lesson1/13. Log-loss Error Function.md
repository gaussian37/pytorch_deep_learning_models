![1](https://i.imgur.com/oXYaTtp.png)

에베레스트 산 꼭대기에서 땅으로 내려가려고 하는데 구름이 많다고 가정합시다.

![2](https://i.imgur.com/wYvrx5m.png)

이 때에는 가능한 모든 방향으로 이동하면서 내려갈 수 있습니다. 이 때 우리는 가장 많이 내려갈 수 있는 방향으로 선택을 하게 됩니다.

![3](https://i.imgur.com/mXo2gff.png)

특정 방향을 정하여 내려가게 되면 해발 고도(높이)를 줄이면서 내려 옵니다. 

![4](https://i.imgur.com/IZugxvn.png)

특정 지점까지 최대한 내려왔다면 다시 모든 방향에서 최대한 내려갈 수 있는 방향을 선택하여 내려갑니다.

![5](https://i.imgur.com/ZyzqRmx.png)

이렇게 해발 고도(height)를 최소화 하는 방향으로 지면까지 내려오게 됩니다.

![6](https://i.imgur.com/DyWUR0Z.png)

이 때 우리가 산을 내려오는 데 Key로 사용한 요소는 Height 입니다. 여기서 Height는 Error에 해당합니다. 

Height(Error)는 우리의 solution(지면)과 얼마나 떨어져 있는지 나타내는 지표입니다. 

우리의 목적은 Height(Error)를 지속적으로 줄여 지면에 도달하는 것입니다.

![7](https://i.imgur.com/UEvOu1U.png) 

만약에 지면이 아닌 굴곡(Valley)에 빠지면 어떻게 될까요? 

우리가 원하는 이상적인 solution(지면)은 아닙니다. 이것을 local minimum이라고 합니다. 

이러한 local minimum에 갇히는 현상은 머신러닝에서 자주 일어납니다. 

이러한 local minimum 문제를 해결하는 방법인 gradient descent는 추후에 다루겠습니다.

![8](https://i.imgur.com/q6HB7eE.png)

다시 Error에 대하여 생각해 봅시다. 여기서 2개의 클래스로 분류하는 가장 이상적인 방법은 무엇일까요?

![9](https://i.imgur.com/aUEw9TS.png)

먼저 위와 같이 분류를 하면 Error 는 2개 입니다. 에베레스트 산 예제에서 보면 height = 2가 되는 셈입니다.

에베레스트 예제와 같이 Error를 줄이기 위해서 descent 할 수 있는 모든 방향을 살펴본 뒤 Error를 줄여나아가야 합니다. 

![10](https://i.imgur.com/CKIT9zr.png)

Line을 조금 움직여 Error = 1로 만들어 봅니다.

![11](https://i.imgur.com/5W1784J.png)

위와 같이 최종적으로 Error = 0 으로 만들 수 있습니다.

![12](https://i.imgur.com/1NNC9we.png)

이 문제를 풀어가는 데에는 작은 문제점이 하나 있었습니다. 왜 step을 조금씩 움직여서 Error = 0 을 찾아갔을까요?

이유는 이 조그만 step은 derivative에 의해 계산되기 때문입니다. 그러면 이 조그만 step으로 변경을 하면 어떻게 진행이 될까요?

![13](https://i.imgur.com/hXg8v23.png)

![14](https://i.imgur.com/0X7wM4L.png)

위와 같이 Line을 조금씩 움직이게 되어 Error가 개선이 안되고 있습니다. 여기서 우리가 할 수 있는 방법이 많이 없습니다.

![15](https://i.imgur.com/1ZNehlC.png)

이것은 마치 평평한 피라미드 계단을 내려가는 것과 비슷합니다. 

Discrete 한 성질을 가지고 있어 모든 방향의 Error = 2라면 다음 step을 어떻게 해야할지 모르게 됩니다.

하지만 에베레스트에서는 Continuous한 성질을 가지고 있어 어떤 방향으로 내려가야 할 지 정할 수 있습니다.

![16](https://i.imgur.com/kzsCqHm.png)

가장 Error를 최소화 하는 방향으로 내려가면 됩니다.

![17](https://i.imgur.com/9WXYysL.png)

즉, 이것은 <span style="background-color: #FFFF00">Gradient Descent를 사용할 때, Error function은 반드시 Continuous 해야 한다는 성질</span>을 나타냅니다.

에베레스트에서는 조그만 변화가 지속 반영되지만, 피라미드에서는 조그만 변화가 지속 반영되지 않고 2 → 1 → 0 으로 변할 뿐입니다.

또한 <span style="background-color: #FFFF00">Error function은 반드시 Differentiable(미분 가능) 해야 합니다.</span> 이것에 대해서는 추후에 알아보겠습니다.

![18](https://i.imgur.com/5zvEgys.png)

Error Function은 continuous하고 이 성질에 따라 진행해 보겠습니다.

먼저 위와 같이 분류하였을 때 파란색 2개, 빨간색 2개는 정확히 분류되었고 파란색, 빨간색 각각 1개씩 오 분류 되었습니다.

![19](https://i.imgur.com/fIjRDQr.png)

Error function은 2개의 오 분류 된 점에 대해서는 큰 페널티를 주고 맞게 분류된 4개의 점은 작은 페널티를 주게 됩니다.

페널티는 경계선과의 거리가 됩니다. 즉, 오 분류가 된 점은 이 거리를 크게 잡고 맞게 분류되면 이 거리를 0에 가깝게 잡습니다.

정확한 수식은 추후에 자세히 다루겠습니다.

![20](https://i.imgur.com/YAVxySK.png)

Error의 총합은 위와 같습니다. 이 때 우리가 해야할 방법은 Line을 조정하여 Error의 총합을 작게 하는 것입니다. 

![21](https://i.imgur.com/nI5DMt8.png)

이전에 각각의 점의 갯수를 이용하여 Error = 2 → 1 → 0 으로 줄여가면 어떤 방향으로 움직여야 하는지 알 수 어려웠습니다.

반면 위와 같이 Error의 총합으로 continuous하게 계산한다면 어떤 방향으로 Line을 움직여야 할 지 알 수 있습니다. 

위와 같이 Line을 움직이면 Error의 총 합이 작아지게 됩니다.

![22](https://i.imgur.com/OKKt3Zm.png)

이러한 방법으로 Error function을 설계하게 되면 문제를 풀기 위하여 gradient descent를 사용할 수 있게 됩니다. 

![23](https://i.imgur.com/3midxUp.png)

위에서 Error는 height 이고 이것은 파란/빨간 점들의 합입니다. 

우리는 높이를 최대한 낮추는 방향으로 내려올 것입니다. 

이것은 Error의 합을 최대한 줄이는 방향으로 Line을 움직이는 것과 동일합니다.

![24](https://i.imgur.com/gvb397f.png) 
Height를 낮출 수 있는 방향으로 내려 왔습니다. 즉, Line을 움직여 새로운 Error의 합을 줄였습니다.

그러면 이러한 Error의 합을 계산하는 Error Function은 어떻게 설계할까요? 이것은 다음 강의에서 살펴보도록 하겠습니다.