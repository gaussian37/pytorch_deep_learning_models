{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlp with mnist dataset with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-77dbbb0df974>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\gauss\\Anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight & Bias for nn layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(name = \"W1\", initializer= tf.random_normal([784, 256]))\n",
    "b1 = tf.get_variable(name = \"b1\", initializer= tf.random_normal([256]))\n",
    "a1 = tf.nn.relu(tf.matmul(X, W1) + b1) # (?, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(name = \"W2\", initializer= tf.random_normal([256, 256]))\n",
    "b2 = tf.get_variable(name = \"b2\", initializer= tf.random_normal([256]))\n",
    "a2 = tf.nn.relu(tf.matmul(a1, W2) + b2) # (?, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(name = \"W3\", initializer= tf.random_normal([256, 10]))\n",
    "b3 = tf.get_variable(name = \"b3\", initializer= tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(a2, W3) + b3 # (?, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \t loss : 43.5949\n",
      "Epoch : 1 \t loss : 8.3581\n",
      "Epoch : 2 \t loss : 4.5213\n",
      "Epoch : 3 \t loss : 3.0077\n",
      "Epoch : 4 \t loss : 2.2337\n",
      "Epoch : 5 \t loss : 1.7791\n",
      "Epoch : 6 \t loss : 1.7054\n",
      "Epoch : 7 \t loss : 1.6072\n",
      "Epoch : 8 \t loss : 1.5188\n",
      "Epoch : 9 \t loss : 1.2151\n",
      "Epoch : 10 \t loss : 1.0503\n",
      "Epoch : 11 \t loss : 0.9019\n",
      "Epoch : 12 \t loss : 0.8049\n",
      "Epoch : 13 \t loss : 0.6331\n",
      "Epoch : 14 \t loss : 0.6727\n",
      "Learning finished\n",
      "Accuracy : 0.96\n",
      "Sample : [8], Prediction : [8]\n"
     ]
    }
   ],
   "source": [
    "# For GPU user\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = 0\n",
    "        total_batches = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "        for i in range(total_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {X:batch_x, Y:batch_y}\n",
    "            _loss, _ = sess.run([loss, optimizer], feed_dict = feed_dict)\n",
    "            avg_loss += _loss / total_batches\n",
    "\n",
    "        print(\"Epoch : {:d} \\t loss : {:.4f}\".format(epoch, avg_loss))\n",
    "        \n",
    "    print(\"Learning finished\")   \n",
    "    \n",
    "    # Test model and check accuracy    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : {:.2f}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels})))\n",
    "    \n",
    "    # Get one and predict it\n",
    "    r = random.randint(0, mnist.test.num_examples-1)\n",
    "    print(\"Sample : {}, Prediction : {}\".format(\n",
    "        sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)),\n",
    "        sess.run(tf.argmax(hypothesis, 1), feed_dict={X:mnist.test.images[r:r+1]})))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
